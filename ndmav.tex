\documentclass[10pt,t]{beamer}

\title{Learning Sum-Product Networks}
\author{Nicola Di Mauro \and Antonio Vergari}
\date{September 2016}

\setbeamerfont{footnote}{size=\scriptsize}
\addtobeamertemplate{footnote}{}{\vspace{6pt}}

\begin{document}

\begin{frame}
\maketitle
\end{frame}

\begin{frame}
\frametitle{The need for SPN}
Sum-Product Networks (SPNs) are a type of probabilistic model\footnote{H. Poon
  and P. Domingos, \emph{Sum-Product Network: a New Deep Architecture}, UAI 2011}
\begin{itemize}
\item for Pobabilistic Graphical Models (PGMs) there exist multi-purpose
  inference tools
\begin{itemize}
\item the computational
effort scales unproportional to the complexity of the graph
\item solution: using approximate inference
\end{itemize}
\end{itemize}
SPNs represent probability distributions and a corresponding exact inference
machine for the represented distribution at the same time 
\end{frame}

\begin{frame}
\frametitle{Representation}
\end{frame}

\begin{frame}
\frametitle{Interpretation}
\begin{itemize}
\item probabilistic model
\item deep feedforward neural network
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Network Polynomials}
\end{frame}

\begin{frame}
\frametitle{Arithmetic Circuits}
\begin{itemize}
\item SPNs are a special case of ACs
\item Learning Sum-Product Networks with Direct and Indirect Variable Interactions
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Inference(s)}
\end{frame}

\begin{frame}
\frametitle{Parameter Learning}
\end{frame}

\begin{frame}
\frametitle{Structure Learning}
\end{frame}

\begin{frame}
\frametitle{SPN Understanding}
\end{frame}

\begin{frame}
\frametitle{(SPN-based) Representation Learning}
\end{frame}


\begin{frame}
\frametitle{Applications}
\end{frame}

\begin{frame}
\frametitle{Code}
\end{frame}



\begin{frame}
\frametitle{Open Problems and Future Investigations}
\end{frame}






\end{document}